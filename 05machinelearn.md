### 01 机器学习

### 03 训练模型
**居中趋势测量**：均值、中值、众数。
**数据的离散性**：四分位距法、异常值、标准偏差、贝塞尔修正。

### 04 检测错误
**过拟合**：太过具体，训练集表现很好，倾向于记住非学习
较低的训练误差，较高的测试误差
**欠拟合**：较高的训练误差，测试误差

#### 04.01 K折交叉验证
K折交叉验证是在优化模型时，将数据分为K等份，其中K-1份作为训练数据，1份作为测试数据。随后做交叉验证的时候，每次采用数据的其中1份作为测试集，计算模型的准确率。最终可以计算出K个准确率，利用K各准确率的平均值作为模型的准确度衡量。

#### 04.02 网格搜索
网格搜索是用在选择模型参数的过程中。尝试所有的模型参数进行拟合，从中搜索到最佳的模型参数。之所以成为网格搜索，因为是在参数所建立的多维网格中找到最佳的参数点。

#### 04.03 K折交叉验证与网格搜索
网格搜索不使用交叉验证，使训练速度更快，但可能难以得到最优的模型参数；交叉验证对每一个参数组合得出的评分更为准确和鲁棒，提高评估的稳定性。

#### 04.04 学习曲线
![学习曲线](https://i.imgur.com/vFRX1dP.png)
- 欠拟合，随着训练集增加，训练误差和测试误差接近。
- 良好拟合，随着训练集增加，训练误差和测试误差接近，此时误差较欠拟合低。
- 过拟合，随着训练集增加，训练误差和测试误差接近，但是训练误差和测试误差相差较欠拟合大一些。交叉误差始终不会太低。

### 06 评估指标
#### 06.01 混淆矩阵
![混淆矩阵](https://i.imgur.com/K7TfktM.png)
#### 06.02 准确率
分类正确的(真阳真阴)/总树木
#### 06.03 准确率不适用的情形
可能会忽略一些点。
比如要找到信用卡不良的记录。

#### 06.05 精度和召回率
1. 对医疗来说，假阴不可接受，假阳可以。(高召回率)
因为健康的人可以识别为有病，但有病不能识别为健康。
2. 对垃圾邮件来说，假阴可以接受，假阳却不能。(高精度)
因为垃圾邮件可以接受，但正确邮件不能丢失。

#### 06.05 精度和召回率 计算
| ——— | Diagnosed sick | Diagnosed Healthy | 召回率recall |
| ---------- | :---------- : | ----------: |
| sick       | 正阳 | 假阴 | 正阳/(正阳+假阴)|
| healthy    | 假阳 | 假阳 |   |
|精确度precision| 正阳/(正阳+假阳)|            |


#### 06.08 F1得分
![F1得分](https://i.imgur.com/3A8Y6mQ.png)

#### 06.09 Fβ得分
![fβ得分](https://i.imgur.com/B0cj2yH.png)
- β越小越偏向于精度，反之召回。
```
1对于宇宙飞船，我们不允许出现任何故障零件，可以检查本身能正常运转的零件。因此，这是一个高召回率模型，因此 β = 2。
2对于通知模型，因为是免费发送给客户，如果向更都的用户发送邮件也无害。但是也不能太过了，因为可能会惹怒用户。我们还希望找到尽可能多感兴趣的用户。因此，这个模型应该具有合适的精度和合适的召回率。β = 1 应该可行。
3对于促销材料模型，因为发送材料需要成本，我们不希望向不感兴趣的用户发送材料。因此是个高精度模型。β = 0.5 应该可行。
```
###### F-β得分的界限
![fβ得分的界限](https://i.imgur.com/xCinhF3.png)

#### 06.10 ROC曲线
![ROC曲线](https://i.imgur.com/UhjXxPI.png)
- roc曲线面积越接近于1,模型就越好

#### 06.11 决定系数 R2 
R2的数值范围从0至1，表示目标变量的预测值和实际值之间的相关程度平方的百分比。一个模型的R2 值为0还不如直接用平均值来预测效果好；而一个R2 值为1的模型则可以对目标变量进行完美的预测。从0至1之间的数值，则表示该模型中目标变量中有百分之多少能够用特征来解释。模型也可能出现负值的R2，这种情况下模型所做预测有时会比直接计算目标变量的平均值差很多。
```
def performance_metric2(y_true, y_predict):
    """计算并返回预测值相比于预测值的分数"""
    y_mean = sum(y_true)/len(y_true)
    sst = sum(map(lambda x:(x-y_mean)**2, y_true))
    ssr = sum([(x-y)**2 for x, y in zip(y_true, y_predict)])
    score = 1- ssr/sst
    return score
```

![决定系数](https://i.imgur.com/Hq15eSP.png)

[决定系数](https://en.wikipedia.org/wiki/Coefficient_of_determination)


ssr:(训练模型得到的结果-平均值) *(训练模型得到的结果-平均值)之和

sst:(实际值-平均值) *(实际值-平均值)之和

sse:(实际值-训练模型得到的结果)*(实际值-训练模型得到的结果)之和
