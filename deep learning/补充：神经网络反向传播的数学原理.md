### 补充：神经网络反向传播的数学原理

![9db015cf20d7f569eae57761c0dade47_r.jpg](https://i.imgur.com/aRLVDj1.jpg)

总误差：

E<sub>total</sub> = E<sub>o1</sub> + E<sub>o2</sub> = 0.5 * (target<sub>o1</sub> - out<sub>o1</sub>)<sup>2</sup> + 0.5 * (target<sub>o2</sub> - out<sub>o2</sub>)<sup>2</sup>

其中output就是刚刚通过前向传播算出来的out<sub>o1</sub>、out<sub>o2</sub>；target是节点o1、o2的目标值。E<sub>total</sub>用来衡量二者的误差。


对输出层的w5：
通过梯度下降调整w5，需要求∂E<sub>total</sub>/∂w5，由链式法则：

![roundw5.png](https://i.imgur.com/EUbhIwf.png)

如下图所示：

![f2d8768af0d9264687905a0134dae927_r.jpg](https://i.imgur.com/RBXnUwe.jpg)

![roundw5_2.png](https://i.imgur.com/5OQ7KTq.png)


以上3个相乘得到梯度∂E<sub>total</sub>/∂w5


对隐藏层的w1：

通过梯度下降调整w1，需要求 ∂E<sub>total</sub>/∂w1 由链式法则：

![roundw5_3.png](https://i.imgur.com/RDY8QOm.png)

如下图所示：

![d50d1d812f0f036b8c5cb389e463b01a_r.jpg](https://i.imgur.com/BtW1tse.jpg)

参数w1影响了net<sub>h1</sub>，进而影响了out<sub>h1</sub>，之后又影响到E<sub>o1</sub>、E<sub>o2</sub>。
求解每个部分：

![roundw5_4.png](https://i.imgur.com/rlG3OCC.png)

其中

![roundw5_5.png](https://i.imgur.com/c5WTDeG.png)

详细见：[如何理解神经网络里面的反向传播算法？](https://www.zhihu.com/question/24827633/answer/91489990 "如何理解神经网络里面的反向传播算法？")