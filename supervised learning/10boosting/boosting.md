### 01 集成学习的简单规则 
先通过某个数据子集进行学习，形成某个规则，然后通过另一个数据子集进行学习，形成不同的规则，接着通过另一个数据子集进行学习，形成第三个规则，接着更多；最后收集所有这些规则，并将他们合并成为复杂的规则。

#### 为什么考虑子集，而不考虑所有数据？
因为如果考虑所有数据的话，就很难在想到这些简单规则。

### 02 集成学习算法
挑选子集的时候遵守均匀规则。

### 06 集成Boosting
- 不再是随机均匀选择数据，而是选择表现不太好(最难)的那些样本。
- 加权均值，避免求整个均值。

### 07 AdaBoost简介
![Adaboost](https://i.imgur.com/v4D4wg1.jpg)
