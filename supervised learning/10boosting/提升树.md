1. 平方误差损失函数用于回归问题
2. 指数损失函数用于分类问题

### 提升树模型
提升树模型可以表示为决策树的加法模型

![boost_tree_1.png](https://i.imgur.com/66eVCNJ.png)

其中，T(x;θ<sub>m</sub>)表示决策树；θ<sub>m</sub>表示决策树的参数；M为树的个数

### 提升树算法
提升树算法采用前向分步法，首先确定初始提升树f<sub>0</sub>(x)=0，第m步的模型是

![boost_tree_2.png](https://i.imgur.com/kVHXfY6.png)

其中，f<sub>m-1</sub>(x)为当前模型，通过经验风险极小化确定下一颗决策树的参数θ<sub>m</sub>,

![boost_tree_3.png](https://i.imgur.com/wrpus6R.png)

### 回归问题的提升树算法
输入：训练数据集T={(x<sub>1</sub>,y<sub>1</sub>),(x<sub>2</sub>,y<sub>2</sub>),...,(x<sub>N</sub>,y<sub>N</sub>)}；![boost_tree_4.png](https://i.imgur.com/eHNQkF5.png)

输出：提升树 f<sub>M</sub>(x)

(1) 初始化f<sub>0</sub>(x) = 0
(2) 对m=1,2,...,M
(a) 计算残差

![boost_tree_5.png](https://i.imgur.com/g1b3VWb.png)

(b) 拟合残差r<sub>mi</sub>学习一个回归树，得到T(x;θ<sub>m</sub>)
(c) 更新 f<sub>m</sub>(x) = f<sub>m-1</sub>(x) + T(x;θ<sub>m</sub>)

(3) 得到回归问题提升树：

![boost_tree_6.png](https://i.imgur.com/ausFV8O.png)


### 梯度提升算法

输入：训练数据集T={(x<sub>1</sub>,y<sub>1</sub>),(x<sub>2</sub>,y<sub>2</sub>),...,(x<sub>N</sub>,y<sub>N</sub>)}；![boost_tree_4.png](https://i.imgur.com/eHNQkF5.png)，损失函数L(y,f(x))

输出：回归树 fhat(x)

(1) 初始化

![boost_tree_7.png](https://i.imgur.com/cMgPG5Z.png)

(2) 对m=1,2,...,M
(a) i=1,2,...,N 计算

![boost_tree_8.png](https://i.imgur.com/O7J47PL.png)

(b) 对r<sub>mi</sub>拟合一个回归树，得到第m棵树的叶节点区域R<sub>mj</sub>，j=1,2,...,J
(c) 对j=1,2,...,J，计算

![boost_tree_9.png](https://i.imgur.com/OVETFnF.png)

(d) 更新

![boost_tree_10.png](https://i.imgur.com/S4dKkYj.png)

(3) 得到回归树

![boost_tree_11.png](https://i.imgur.com/QQYyXYI.png)