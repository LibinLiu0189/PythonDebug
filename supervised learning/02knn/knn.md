### 00 knn
### 01 KNN偏差
**近似误差**，模型估计值与实际值之间的差距。
更关注于“训练”。

最小化近似误差，即为使估计值尽量接近真实值，但是这个接近只是对训练样本（当前问题）而言，模型本身并不是最接近真实分布。换一组样本，可能就不近似了。这种只管眼前不顾未来预测的行为，即为过拟合。

**估计误差**，模型的估计系数与实际系数之间的差距。
更关注于“测试”、“泛化”。

最小化估计误差，即为使估计系数尽量接近真实系数，但是此时对训练样本（当前问题）得到的估计值不一定是最接近真实值的估计值；但是对模型本身来说，它能适应更多的问题（测试样本）。

![M次多项式函数拟合问题的例子](https://pic1.zhimg.com/v2-d944c057e85de7c847dea5ca61ee6dc0_r.jpg)
如上图中对于这个训练集而言，其实选择3次多项式来作为预测模型是与实际模型最符合的，可是当选择9次多项式的话（对应k值越小），虽然对训练集的预测非常准确（近似误差越小），但是这是一个明显的过度拟合问题（overfitting），得出的预测模型的估计误差相对于3次多项式其实是更大的。
[如何理解和区分近似误差和估计误差?](https://www.zhihu.com/question/60793482 "如何理解和区分近似误差和估计误差?")

#### 02.01 曼哈顿距离
在平面上，坐标（x1, y1）的i点与坐标（x2, y2）的j点的曼哈顿距离为：
```
d(i,j)=|X1-X2|+|Y1-Y2|
```

#### 02.02 欧氏距离(欧几里得度量)
二维空间中的欧氏距离
```
0ρ = sqrt( (x1-x2)^2+(y1-y2)^2 )　|x| = √( x2 + y2 )
```

### 03 维度灾难
每次添加一个新特征时，就是将另一个维度加至你的输入空间，需要指数级的增加数据，从而可以进行准确的泛化。

1. 维度加权
2. 选择k,如果k=n,可以对较近的点加权


### 04 局部加权回归
![加权的J函数](http://img.blog.csdn.net/20160720154847377)
其中w(i)是权重，它根据要预测的点与数据集中的点的距离来为数据集中的点赋权值。当某点离要预测的点越远，其权重越小，否则越大。

一个比较好的权重函数如下：
![权重函数](http://img.blog.csdn.net/20160720155155460)
该函数称为指数衰减函数，其中**k**为波长参数，它控制了**权值随距离下降的速率**，该函数形式上类似高斯分布(正态分布)，但并没有任何高斯分布的意义。
[局部加权回归](http://blog.csdn.net/herosofearth/article/details/51969517 "局部加权线性回归")