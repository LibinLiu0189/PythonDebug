### 决策树应用算法

![dt_1.png](https://i.imgur.com/P0LSN3z.png)

### 1.0 ID3
#### 1.1.0 信息增益的算法
增益表示分类目标的熵减去当前属性的熵，增益越大，分类能力越强。

输入：训练数据集D和特征A;

输出：计算特征A对训练数据集D的信息增益g(D，A)

(1) 计算数据集D的经验熵H(D)

分类目标的熵叫作经验熵，表示数据集分类D的不确定性。

![tree_1.png](https://i.imgur.com/hFQ1rsp.png)

(2) 计算特征A对数据集D的经验条件熵H(D|A)

当前属性的熵就是经验条件熵，表示在给定A的条件下对数据分类D的不确定性。

![tree_2.png](https://i.imgur.com/0vY5lwT.png)

(3) 计算信息增益
经验熵H(D)、经验条件熵H(D|A)两者相减叫作互信息。


![tree_3.png](https://i.imgur.com/afB7oam.png)

#### 1.1.1 ID3原理
原理：每次选取当前最佳的特征来分割数据，并按照该特征的所有可能取值来切分。

### 1.2 ID3的缺陷
#### 1.2.1 ID3 缺陷:切分方式过于迅速
也就是说，如果一个特征有 4 种取值，那么数据将被切分成 4 份。一旦按照某特征切分后，该特征在之后的算法执行过程中将不会再起作用，所以有观点认为这种**切分方式过于迅速**。

#### 1.2.2 ID3 缺陷: 不能直接处理连续型特征
只有事先将连续型特征转换成离散型，才能在 ID3 算法中使用。但这种转换过程会破坏连续型变量的内在性质。

举例：

如果我们在上面的数据记录中加一个姓名属性，假设14条记录中的每个人姓名不同，那么信息增益就会选择姓名作为最佳属性，因为按姓名分裂后，每个组只包含一条记录，而每个记录只属于一类（要么购买电脑要么不购买，信息量计算为1/14(-1/1log1/1-0/1log0/1)\*14=0，信息增益最大），因此纯度最高，以姓名作为测试分裂的结点下面有14个分支。但这样的分类没有意义，它没有任何泛化能力。

#### 1.2.3 二元切分法
另外一种方法是二元切分法，即每次把数据集切分成两份。如果数据的某特征值等于切分所要求的值，那么这些数据就进入树的左子树，反之则进入树的右子树。

另外，二元切分法也节省了树的构建时间，但这点意义也不是特别大，因为这些树构建一般是离线完成，时间并非需要重点关注的因素。

### 1.2 C4.5 信息增益率
#### 1.2.1 C4.5 信息增益率
信息增益值的大小是相对于训练数据集而言的，并没有绝对意义。

在分类问题困难时，也就是说在训练数据集的经验熵大的时候，信息增益值会偏大。

反之，信息增益值偏小。当经验熵很大时，训练出来的形状是一棵庞大且深度很浅的树，这样的划分是极为不合理的。

使用信息增益比可以对这一问题进行校验。

![dt_c4.5_1.png](https://i.imgur.com/QuQHs3k.png)

#### 1.2.2 优缺点
##### 优点
1.用信息增益率来选择属性，克服用信息增益选择属性时偏向选择特征属性值多的不足。

2.能够完成对连续属性的离散化处理

3.在构造过程中进行剪枝

4.能够对不完整数据进行处理

##### 缺点
1.子构造树的过程中需要进行多次的扫描和排序，所以它的运行效率低。

2.只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。

### 1.3 CART
背景：ID3 C4.5都是基于信息熵，Gini系数能够简化模型(不用计算log等等)且不失去熵模型的特点。

CART是一棵二叉树，采用二元切分法，每次把数据切成两份，分别进入左子树、右子树。而且每个非叶子节点都有两个孩子，所以CART的叶子节点比非叶子多1。

相比ID3和C4.5，CART应用要多一些，既可以用于分类也可以用于回归。

CART分类时，使用基尼指数（Gini）来选择最好的数据分割的特征，gini描述的是纯度，与信息熵的含义相似。CART中每一次迭代都会降低GINI系数。

回归时，使用均方差作为loss function。

#### 1.3.1 Gini系数 分类误差率
![dt_gini_1.png](https://i.imgur.com/v7rgrMa.jpg)

从上图可以看出，基尼系数和熵之半的曲线非常接近，仅仅在45度角附近误差稍大。因此，基尼系数可以做为熵模型的一个近似替代。而CART分类树算法就是使用的基尼系数来选择决策树的特征。

同时，为了进一步简化，CART分类树算法每次仅仅对某个特征的值进行二分，而不是多分，这样CART分类树算法建立起来的是二叉树，而不是多叉树。

这样一可以进一步简化基尼系数的计算，二可以建立一个更加优雅的二叉树模型。

#### 1.3.2 CART原理
在分类问题中，假设有K个类别，第k个类别的概率为pk, 则基尼系数的表达式为：

![gini_1.png](https://i.imgur.com/LEjAZbq.png)

如果是二类分类问题，计算就更加简单了，如果属于第一个样本输出的概率是p，则基尼系数的表达式为：

![gini_2.png](https://i.imgur.com/1bZUuhF.png)

对于个给定的样本D,假设有K个类别, 第k个类别的数量为Ck,则样本D的基尼系数表达式为：

![gini_3.png](https://i.imgur.com/9XIQU78.png)

特别的，对于样本D,如果根据特征A的某个值a,把D分成D1和D2两部分，则在特征A的条件下，D的基尼系数表达式为：

![gini_4.png](https://i.imgur.com/HEyb87y.png)

CART选择Gini(D,A)最小的特征作为划分特征。

#### 1.3.3 CART优缺点
1.能够处理大量特征的分类，并且不用做特征选择。

2.在训练完成后能给出那些feature比较重要

3.训练速度快

4.很容易并行

5.实现相对来说比较简单

### 1.4 gini系数
基尼系数是量度贫富悬殊程度的标量。它的定义如下：我们首先收集社会上每一个人的总财富额，把它从少至大排序，计算它的累积函数（cumulative function），然后便可绘出图中的洛仑兹曲线（Lorenz curve）。图中横轴是人口比例的累积分布，竖轴是财富比例的累积分佈

![cumulative share of people from lowest to highest incomes](https://pic3.zhimg.com/de0f5d4c743a22f8918106236a98c32c_r.jpg)

A和B是图中两面积，基尼系数便是![gini计算](https://www.zhihu.com/equation?tex=%5Cfrac%7BA%7D%7BA%2BB%7D)；

gini用来度量分布的不均匀性，总体类别越杂乱，gini指数就越大。

#### 1.4.1 代码实现
```
import numpy as np

def gini_coef(wealths):
    cum_wealths = np.cumsum(sorted(np.append(wealths, 0)))
    sum_wealths = cum_wealths[-1]
    xarray = np.array(range(0, len(cum_wealths))) / np.float(len(cum_wealths)-1)
    yarray = cum_wealths / sum_wealths
    B = np.trapz(yarray, x=xarray)
    A = 0.5 - B
    return A / (A+B)
```


### 2.0 划分分支方式
- ID3 是信息增益分支
- C4.5 是信息增益率分支
- CART 做分类工作时，采用 GINI 值作为节点分裂的依据；回归时，采用样本的最小方差作为节点的分裂依据。

特征离散 目标离散：使用ID3 CART

特征连续 目标离散：将连续的特征离散化，使用ID3 CART

**工程上总的来说**:
CART 和 C4.5 之间主要差异在于分类结果上，CART 可以回归分析也可以分类，C4.5 只能做分类；C4.5 子节点是可以多分的，而 CART 是无数个二叉子节点；

参考：

[为什么说c45克服了ID3偏向选择取值较多的属性的这一问题？](https://www.zhihu.com/question/27109632 "为什么说c45克服了ID3偏向选择取值较多的属性的这一问题？")

[C45为什么使用信息增益比来选择特征？](https://www.zhihu.com/question/22928442 "C45为什么使用信息增益比来选择特征？")

[决策树算法原理(上)](http://www.cnblogs.com/pinard/p/6050306.html)

[决策树算法原理(下)](https://www.cnblogs.com/pinard/p/6053344.html "决策树算法原理(下)")

[C4.5 算法对于连续性属性的处理方法介绍](https://blog.csdn.net/shenxiaoming77/article/details/51602976)

[cart算法为什么选用gini指数？](https://www.zhihu.com/question/36659925)